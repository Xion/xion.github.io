<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="http://xion.io/$theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="http://xion.io/$theme/stylesheet/pygments.min.css">
  <link rel="stylesheet" type="text/css" href="http://xion.io/$theme/stylesheet/font-awesome.min.css">

    <link href="http://xion.io/style.css" rel="stylesheet">




  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />

<meta name="author" content="Karol Kuczmarski" />
<meta name="description" content="Celery is an asynchronous task worker that’s frequently used for background processing in Python web apps. Rather than performing a time-consuming task within the request loop, we delegate it to a queue so that a worker process can pick it up when ready. The immediate benefit is much better latency for the end user. Pros also include easier scalability, since you can adjust the number of workers to your task load. Examples of tasks that are usually best done in the background vary from fetching data through a third-party API to sending emails, and from pushing mobile notifications to pruning the database of stale records. Anything that may take more than a couple hundred milliseconds to complete — and isn’t absolutely essential to the current HTTP request — is typically a good candidate for asynchronous processing. In Celery, workers are just regular Python processes, often running the exact same code that’s powering the app’s web frontend1. But unlike most of that code, they aren’t servicing any HTTP requests — they simply run some function with given arguments, both specified by whomever sent a task for execution. Indeed, those functions don’t even know who or what asked for them to be executed. Neat, right? It is what we usually compliment as decoupling, or separation of concerns. They are valuable qualities even regardless of the UI and scaling benefits mentioned earlier. Not quite web But those qualities come with a trade-off. Task code is no longer a web frontend code: it doesn’t run within the comfy environment of our web framework of choice. Losing it may be quite unnerving, actually, because in a typical web application there will be many things tied directly to the HTTP request pipeline. After all, this is what web applications do — respond to HTTP requests — so it often makes perfect sense e.g. to marry the request flow with database transactions, committing or rolling those back according to HTTP status code that the app produced. Tasks may also require a database, though, if only to assert the expected state of the world. Similar goes for memcache, a Redis instance, or basically any resource used by the frontend code. Alas, it’s quite possible the very reason we delegate work to a task is to shift lengthy interactions with those external systems away from the UI. Obviously, we’re going to need them for that! Fake a request So one way or another, our tasks will most likely need some initialization and/or cleanup code. And since it’s probably the same code that most HTTP request handlers require and use already, why not just pretend we’re handling a request after all? In Flask, we can pull that off rather easily. The test_request_context method is conveniently provided to allow for faking the request context — that is, an execution environment for HTTP handlers. Like the name suggest, it is used mostly for testing, but there is nothing stopping us from using it in tasks run by Celery. We probably don’t want to call it directly, though. What would be better is to have Celery prepare the context first, and then run the task code as if it was an HTTP handler. For even better results, the context would preserve information extracted from the actual HTTP request, one that has sent the task for execution. Moving some work to the background would then be a trivial matter, for both the task and the original handler would operate within the same environment. Convenient? I believe so. And as I’ll demonstrate next, it isn’t very complicated to implement either. Wrap the decorator? At least one piece of the solution should stand out as pretty obvious. Since our intention is to wrap the task’s code in some additional packaging — the request context — it seems fairly natural to write our own @task decorator: import functools from myapp import app, celery def task(**kwargs): &#34;&#34;&#34;Decorator function to apply to Celery tasks. Executes the actual task inside Flask&#39;s test request context. &#34;&#34;&#34; def decorator(func): &#34;&#34;&#34;Actual decorator.&#34;&#34;&#34; @celery.task(**kwargs) @functools.wraps(func) def wrapped(*args, **kwargs): with app.test_request_context(): return func(*args, **kwargs) return wrapped return decorator Here, app is the Flask application, and celery is the Celery object that’s often configured alongside it. The Task class While this technique will give us a request context inside the task code, it won’t be the request context from which the task has been sent for execution. To replicate that context correctly, we need additional support on the sender side. Internally, Celery is converting every function we annotate with @task decorator into a subclass of Celery.app.task.Task. This process can be customized, for example by providing an explicit base= parameter to @task which specifies a custom Task subclass to use in place of the default one. Within that subclass, we’re free to override any functionality that we need to. In our case, we’ll scrape the current request context from Flask for all relevant information, and later use it to recreate the context in the task code. But before we get to that, let’s just create the Task subclass and move the above execution logic to it. This way, users won’t have to use a completely new @task decorator which would needlessly couple them to a specific Celery app instance: from celery import Task class RequestContextTask(Task): &#34;&#34;&#34;Base class for tasks that run inside a Flask request context.&#34;&#34;&#34; abstract = True def __call__(self, *args, **kwargs): with app.test_request_context(): return super(RequestContextTask, self).__call__(*args, **kwargs) Instead, they can either set this class as base= for a specific task: @celery.task(base=RequestContextTask) def sync_user_data(user_id): # ... or make it into new default for all their tasks: celery = Celery(...) celery.Task = RequestContextTask Invocation patterns When the frontend asks for a task to be executed, it most often uses the Task.delay method. It will package a payload contaning task arguments, and send it off through a broker — usually an AMQP-based queue, such as RabbitMQ — so that a Celery worker can pick it up and actually execute. But there are other means of task invocation. We can even run it “in place”, locally and synchronously, which is especially useful for various testing scenarios. Lastly, a task can also be retried from within its own code, terminating its current run and scheduling another attempt for some future date. Obviously, for the RequestContextTask to be useful, it needs to behave correctly in every situation. Therefore we need to cover all the entry points I’ve mentioned — the asynchronous call, a synchronous invocation, and a task retry: class RequestContextTask(Task): # ... def apply_async(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .apply_async(args, kwargs, **rest) def apply(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .apply(args, kwargs, **rest) def retry(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .retry(args, kwargs, **rest) Note that Task.apply_async is being called internally by Task.delay, so it’s only that first method that we have to override. Context in a box As you can deduce right away, the Flask-related magic is meant to go in the _include_context method. The idea is to prepare arguments for the eventual invocation of Flask.test_request_context, and pass them through an extra task parameter. Those arguments are relatively uncomplicated: they are just a medley of various pieces of information that we can easily obtain from the Flask’s request object: from flask import has_request_context, request class RequestContextTask(Task): CONTEXT_ARG_NAME = &#39;_flask_request_context&#39; # ... def _include_request_context(self, kwargs): &#34;&#34;&#34;Includes all the information about current HTTP request context as an additional argument to the task. &#34;&#34;&#34; if not has_request_context(): return context = { &#39;path&#39;: request.path, &#39;base_url&#39;: request.url_root, &#39;method&#39;: request.method, &#39;headers&#39;: dict(request.headers), } if &#39;?&#39; in request.url: context[&#39;query_string&#39;] = request.url[(request.url.find(&#39;?&#39;) + 1):] kwargs[self.CONTEXT_ARG_NAME] = context On the worker side, we simply unpack them and recreate the context: from flask import make_response class RequestContextTask(Task): # ... def __call__(self, *args, **kwargs): call = lambda: super(RequestContextTask, self).__call__(*args, **kwargs) context = kwargs.pop(self.CONTEXT_ARG_NAME, None) if context is None or has_request_context(): return call() with app.test_request_context(**context): result = call() app.process_response(make_response(result or &#39;&#39;)) return result The only tricky part is calling Flask.process_response at the end. We need to do that for the @after_request hooks to execute correctly. This is quite crucial, because those hooks are where you’d normally put important cleanup code, like commit/rollback of the database transaction. Complete solution To see how all those code snippets fit together, see this gist. You may also want to have a look at the article on Celery integration in Flask docs for some tips on how to integrate it with your own project. This isn’t strictly necessary, as Celery supports sending tasks for execution by explicit name. For that request to reach the worker, however, the task broker configuration must be correctly shared between sender and the worker. ↩" />
<meta name="keywords" content="Celery, Flask, Python, queue, request context">
<meta property="og:site_name" content="Karol Kuczmarski's Blog"/>
<meta property="og:title" content="Celery task in a Flask request context"/>
<meta property="og:description" content="Celery is an asynchronous task worker that’s frequently used for background processing in Python web apps. Rather than performing a time-consuming task within the request loop, we delegate it to a queue so that a worker process can pick it up when ready. The immediate benefit is much better latency for the end user. Pros also include easier scalability, since you can adjust the number of workers to your task load. Examples of tasks that are usually best done in the background vary from fetching data through a third-party API to sending emails, and from pushing mobile notifications to pruning the database of stale records. Anything that may take more than a couple hundred milliseconds to complete — and isn’t absolutely essential to the current HTTP request — is typically a good candidate for asynchronous processing. In Celery, workers are just regular Python processes, often running the exact same code that’s powering the app’s web frontend1. But unlike most of that code, they aren’t servicing any HTTP requests — they simply run some function with given arguments, both specified by whomever sent a task for execution. Indeed, those functions don’t even know who or what asked for them to be executed. Neat, right? It is what we usually compliment as decoupling, or separation of concerns. They are valuable qualities even regardless of the UI and scaling benefits mentioned earlier. Not quite web But those qualities come with a trade-off. Task code is no longer a web frontend code: it doesn’t run within the comfy environment of our web framework of choice. Losing it may be quite unnerving, actually, because in a typical web application there will be many things tied directly to the HTTP request pipeline. After all, this is what web applications do — respond to HTTP requests — so it often makes perfect sense e.g. to marry the request flow with database transactions, committing or rolling those back according to HTTP status code that the app produced. Tasks may also require a database, though, if only to assert the expected state of the world. Similar goes for memcache, a Redis instance, or basically any resource used by the frontend code. Alas, it’s quite possible the very reason we delegate work to a task is to shift lengthy interactions with those external systems away from the UI. Obviously, we’re going to need them for that! Fake a request So one way or another, our tasks will most likely need some initialization and/or cleanup code. And since it’s probably the same code that most HTTP request handlers require and use already, why not just pretend we’re handling a request after all? In Flask, we can pull that off rather easily. The test_request_context method is conveniently provided to allow for faking the request context — that is, an execution environment for HTTP handlers. Like the name suggest, it is used mostly for testing, but there is nothing stopping us from using it in tasks run by Celery. We probably don’t want to call it directly, though. What would be better is to have Celery prepare the context first, and then run the task code as if it was an HTTP handler. For even better results, the context would preserve information extracted from the actual HTTP request, one that has sent the task for execution. Moving some work to the background would then be a trivial matter, for both the task and the original handler would operate within the same environment. Convenient? I believe so. And as I’ll demonstrate next, it isn’t very complicated to implement either. Wrap the decorator? At least one piece of the solution should stand out as pretty obvious. Since our intention is to wrap the task’s code in some additional packaging — the request context — it seems fairly natural to write our own @task decorator: import functools from myapp import app, celery def task(**kwargs): &#34;&#34;&#34;Decorator function to apply to Celery tasks. Executes the actual task inside Flask&#39;s test request context. &#34;&#34;&#34; def decorator(func): &#34;&#34;&#34;Actual decorator.&#34;&#34;&#34; @celery.task(**kwargs) @functools.wraps(func) def wrapped(*args, **kwargs): with app.test_request_context(): return func(*args, **kwargs) return wrapped return decorator Here, app is the Flask application, and celery is the Celery object that’s often configured alongside it. The Task class While this technique will give us a request context inside the task code, it won’t be the request context from which the task has been sent for execution. To replicate that context correctly, we need additional support on the sender side. Internally, Celery is converting every function we annotate with @task decorator into a subclass of Celery.app.task.Task. This process can be customized, for example by providing an explicit base= parameter to @task which specifies a custom Task subclass to use in place of the default one. Within that subclass, we’re free to override any functionality that we need to. In our case, we’ll scrape the current request context from Flask for all relevant information, and later use it to recreate the context in the task code. But before we get to that, let’s just create the Task subclass and move the above execution logic to it. This way, users won’t have to use a completely new @task decorator which would needlessly couple them to a specific Celery app instance: from celery import Task class RequestContextTask(Task): &#34;&#34;&#34;Base class for tasks that run inside a Flask request context.&#34;&#34;&#34; abstract = True def __call__(self, *args, **kwargs): with app.test_request_context(): return super(RequestContextTask, self).__call__(*args, **kwargs) Instead, they can either set this class as base= for a specific task: @celery.task(base=RequestContextTask) def sync_user_data(user_id): # ... or make it into new default for all their tasks: celery = Celery(...) celery.Task = RequestContextTask Invocation patterns When the frontend asks for a task to be executed, it most often uses the Task.delay method. It will package a payload contaning task arguments, and send it off through a broker — usually an AMQP-based queue, such as RabbitMQ — so that a Celery worker can pick it up and actually execute. But there are other means of task invocation. We can even run it “in place”, locally and synchronously, which is especially useful for various testing scenarios. Lastly, a task can also be retried from within its own code, terminating its current run and scheduling another attempt for some future date. Obviously, for the RequestContextTask to be useful, it needs to behave correctly in every situation. Therefore we need to cover all the entry points I’ve mentioned — the asynchronous call, a synchronous invocation, and a task retry: class RequestContextTask(Task): # ... def apply_async(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .apply_async(args, kwargs, **rest) def apply(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .apply(args, kwargs, **rest) def retry(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .retry(args, kwargs, **rest) Note that Task.apply_async is being called internally by Task.delay, so it’s only that first method that we have to override. Context in a box As you can deduce right away, the Flask-related magic is meant to go in the _include_context method. The idea is to prepare arguments for the eventual invocation of Flask.test_request_context, and pass them through an extra task parameter. Those arguments are relatively uncomplicated: they are just a medley of various pieces of information that we can easily obtain from the Flask’s request object: from flask import has_request_context, request class RequestContextTask(Task): CONTEXT_ARG_NAME = &#39;_flask_request_context&#39; # ... def _include_request_context(self, kwargs): &#34;&#34;&#34;Includes all the information about current HTTP request context as an additional argument to the task. &#34;&#34;&#34; if not has_request_context(): return context = { &#39;path&#39;: request.path, &#39;base_url&#39;: request.url_root, &#39;method&#39;: request.method, &#39;headers&#39;: dict(request.headers), } if &#39;?&#39; in request.url: context[&#39;query_string&#39;] = request.url[(request.url.find(&#39;?&#39;) + 1):] kwargs[self.CONTEXT_ARG_NAME] = context On the worker side, we simply unpack them and recreate the context: from flask import make_response class RequestContextTask(Task): # ... def __call__(self, *args, **kwargs): call = lambda: super(RequestContextTask, self).__call__(*args, **kwargs) context = kwargs.pop(self.CONTEXT_ARG_NAME, None) if context is None or has_request_context(): return call() with app.test_request_context(**context): result = call() app.process_response(make_response(result or &#39;&#39;)) return result The only tricky part is calling Flask.process_response at the end. We need to do that for the @after_request hooks to execute correctly. This is quite crucial, because those hooks are where you’d normally put important cleanup code, like commit/rollback of the database transaction. Complete solution To see how all those code snippets fit together, see this gist. You may also want to have a look at the article on Celery integration in Flask docs for some tips on how to integrate it with your own project. This isn’t strictly necessary, as Celery supports sending tasks for execution by explicit name. For that request to reach the worker, however, the task broker configuration must be correctly shared between sender and the worker. ↩"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="http://xion.io/post/code/celery-include-flask-request-context.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2015-11-03 22:40:00-08:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="http://xion.io/">
<meta property="article:section" content="Code"/>
<meta property="article:tag" content="Celery"/>
<meta property="article:tag" content="Flask"/>
<meta property="article:tag" content="Python"/>
<meta property="article:tag" content="queue"/>
<meta property="article:tag" content="request context"/>
<meta property="og:image" content="http://xion.io/logo.jpeg">
  <title>Karol Kuczmarski's Blog &ndash; Celery task in a Flask request context</title>
</head>
<body>
  <aside>
    <div>
      <a href="http://xion.io">
        <img src="http://xion.io/logo.jpeg" alt="Karol Kuczmarski" title="Karol Kuczmarski">
      </a>
      <h1><a href="http://xion.io">Karol Kuczmarski</a></h1>
      <p>fn(Tea) -> Code</p>
      <nav>
        <ul class="list">
          <li><a href="http://xion.io/page/about.html#about">About</a></li>
          <li><a href="http://xion.io/page/projects.html#projects">Projects</a></li>
        </ul>
      </nav>
      <ul class="social">
        <li><a class="sc-github" href="http://github.com/Xion" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-stack-overflow" href="http://stackoverflow.com/users/434799/xion" target="_blank"><i class="fa fa-stack-overflow"></i></a></li>
        <li><a class="sc-twitter" href="http://twitter.com/Xion__" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-google" href="https://plus.google.com/+KarolKuczmarski" target="_blank"><i class="fa fa-google"></i></a></li>
        <li><a class="sc-rss" href="/feeds/atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
      </ul>
    </div>
  </aside>
  <main>
    <nav>
      <a href="http://xion.io">Home</a>
      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>
      <a href="http://xion.org.pl/">Old blog</a>
    </nav>

<article>
  <header>
    <h1 id="celery-include-flask-request-context">Celery task in a Flask request&nbsp;context</h1>
    <p>Posted on Tue 03 November 2015 in <a href="http://xion.io/category/code.html">Code</a></p>
  </header>
  <div>
    <p><a href="http://celeryproject.org">Celery</a> is an asynchronous task worker that&#8217;s frequently used for background processing
in Python web apps. Rather than performing a time-consuming task within the request loop, we delegate it to a <em>queue</em>
so that a <em>worker process</em> can pick it up when ready. The immediate benefit is much better latency for the end user.
Pros also include easier scalability, since you can adjust the number of workers to your task&nbsp;load.</p>
<p>Examples of tasks that are usually best done in the background vary from fetching data through a third-party <span class="caps">API</span>
to sending emails, and from pushing mobile notifications to pruning the database of stale records. Anything that may
take more than a couple hundred milliseconds to complete &#8212; and isn&#8217;t absolutely essential to the current <span class="caps">HTTP</span> request &#8212;
is typically a good candidate for asynchronous&nbsp;processing.</p>
<p>In Celery, workers are just regular Python processes, often running the exact same code that&#8217;s powering the app&#8217;s web
frontend<sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup>. But unlike most of that code, they aren&#8217;t servicing any <span class="caps">HTTP</span> requests &#8212; they simply run some function
with given arguments, both specified by whomever sent a task for execution. Indeed, those functions don&#8217;t even <em>know</em>
who or what asked for them to be&nbsp;executed.</p>
<p>Neat, right? It is what we usually compliment as <em>decoupling</em>, or separation of concerns. They are valuable qualities even
regardless of the <span class="caps">UI</span> and scaling benefits mentioned&nbsp;earlier.</p>
<h4>Not quite&nbsp;web</h4>
<p>But those qualities come with a trade-off. Task code is no longer a web frontend code: it doesn&#8217;t run within the
comfy environment of our web framework of choice. Losing it may be quite unnerving, actually, because in a typical
web application there will be many things tied directly to the <span class="caps">HTTP</span> request pipeline. After all, this is what web
applications <em>do</em> &#8212; respond to <span class="caps">HTTP</span> requests &#8212; so it often makes perfect sense e.g. to marry the request flow
with database transactions, committing or rolling those back according to <span class="caps">HTTP</span> status code that the app&nbsp;produced.</p>
<p>Tasks may also require a database, though, if only to
<a href="http://docs.celeryproject.org/en/latest/userguide/tasks.html#state">assert the expected state of the world</a>.
Similar goes for memcache, a Redis instance, or basically any resource used by the frontend code.
Alas, it&#8217;s quite possible <em>the very reason</em> we delegate work to a task is to shift lengthy interactions with those
external systems away from the <span class="caps">UI</span>. Obviously, we&#8217;re going to need them for&nbsp;that!</p>
<h4>Fake a&nbsp;request</h4>
<p>So one way or another, our tasks will most likely need some initialization and/or cleanup code. And since it&#8217;s probably
the same code that most <span class="caps">HTTP</span> request handlers require and use already, why not just <em>pretend we&#8217;re handling a request
after all</em>?</p>
<p>In <a href="http://flask.pocoo.org">Flask</a>, we can pull that off rather easily.
The <a href="http://flask.pocoo.org/docs/0.10/api/#flask.Flask.test_request_context"><code>test_request_context</code> method</a>
is conveniently provided to allow for faking the <em>request context</em> &#8212; that is, an execution environment for <span class="caps">HTTP</span> handlers.
Like the name suggest, it is used mostly <a href="http://flask.pocoo.org/docs/0.10/testing/">for testing</a>, but there is nothing
stopping us from using it in tasks run by&nbsp;Celery.</p>
<p>We probably don&#8217;t want to call it directly, though. What would be better is to have Celery prepare the context first,
and then run the task code as if it was an <span class="caps">HTTP</span> handler. For even better results, the context would preserve information
extracted from the <em>actual <span class="caps">HTTP</span> request</em>, one that has sent the task for execution. Moving some work to the background
would then be a trivial matter, for both the task and the original handler would operate within the same&nbsp;environment.</p>
<p>Convenient? I believe so. And as I&#8217;ll demonstrate next, it isn&#8217;t very complicated to implement&nbsp;either.</p>
<h4>Wrap the&nbsp;decorator?</h4>
<p>At least one piece of the solution should stand out as pretty obvious. Since our intention is to wrap the task&#8217;s code
in some additional packaging &#8212; the request context &#8212; it seems fairly natural to write our own <code>@task</code> decorator:</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">functools</span>

<span class="kn">from</span> <span class="nn">myapp</span> <span class="kn">import</span> <span class="n">app</span><span class="p">,</span> <span class="n">celery</span>


<span class="k">def</span> <span class="nf">task</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decorator function to apply to Celery tasks.</span>
<span class="sd">    Executes the actual task inside Flask&#39;s test request context.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Actual decorator.&quot;&quot;&quot;</span>
        <span class="nd">@celery.task</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">app</span><span class="o">.</span><span class="n">test_request_context</span><span class="p">():</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapped</span>

    <span class="k">return</span> <span class="n">decorator</span>
</pre></div>


<p>Here, <code>app</code> is the <a href="http://flask.pocoo.org/docs/0.10/api/#application-object"><code>Flask</code> application</a>, and <code>celery</code> is the
<a href="http://docs.celeryproject.org/en/latest/reference/celery.html#celery-application-objects"><code>Celery</code> object</a>
that&#8217;s often configured alongside&nbsp;it.</p>
<h4>The <code>Task</code> class</h4>
<p>While this technique will give us <em>a</em> request context inside the task code, it won&#8217;t be <em>the</em> request context
from which the task has been sent for execution. To replicate that context correctly, we need additional support
on the sender&nbsp;side.</p>
<p>Internally, Celery is converting every function we annotate with <code>@task</code> decorator into a subclass of
<a href="http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task"><code>Celery.app.task.Task</code></a>.
This process can be customized, for example by providing an explicit <code>base=</code> parameter to <code>@task</code> which
specifies a <a href="http://docs.celeryproject.org/en/latest/userguide/tasks.html#custom-task-classes">custom <code>Task</code> subclass</a>
to use in place of the default one. Within that subclass, we&#8217;re free to override any functionality that we need&nbsp;to.</p>
<p>In our case, we&#8217;ll scrape the current request context from Flask for all relevant information,
and later use it to recreate the context in the task&nbsp;code.</p>
<p>But before we get to that, let&#8217;s just create the <code>Task</code> subclass and move the above execution logic to it.
This way, users won&#8217;t have to use a completely new <code>@task</code> decorator which would needlessly couple them to a specific
<code>Celery</code> app&nbsp;instance:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Task</span>

<span class="k">class</span> <span class="nc">RequestContextTask</span><span class="p">(</span><span class="n">Task</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for tasks that run inside a Flask request context.&quot;&quot;&quot;</span>
    <span class="n">abstract</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">app</span><span class="o">.</span><span class="n">test_request_context</span><span class="p">():</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">RequestContextTask</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>


<p>Instead, they can either set this class as <code>base=</code> for a specific&nbsp;task:</p>
<div class="highlight"><pre><span class="nd">@celery.task</span><span class="p">(</span><span class="n">base</span><span class="o">=</span><span class="n">RequestContextTask</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sync_user_data</span><span class="p">(</span><span class="n">user_id</span><span class="p">):</span>
    <span class="c"># ...</span>
</pre></div>


<p>or make it into new default for all their&nbsp;tasks:</p>
<div class="highlight"><pre><span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">celery</span><span class="o">.</span><span class="n">Task</span> <span class="o">=</span> <span class="n">RequestContextTask</span>
</pre></div>


<h4>Invocation&nbsp;patterns</h4>
<p>When the frontend asks for a task to be executed, it most often uses the
<a href="http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.delay"><code>Task.delay</code> method</a>.
It will package a payload contaning task arguments, and send it off through a <em>broker</em> &#8212;
usually an <a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol"><span class="caps">AMQP</span></a>-based queue,
such as <a href="https://www.rabbitmq.com/">RabbitMQ</a> &#8212; so that a Celery worker can pick it up and actually&nbsp;execute.</p>
<p>But there are other means of task invocation. We can even run it
<a href="http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.apply">&#8220;in place&#8221;</a>,
locally and synchronously, which is especially useful for various testing scenarios. Lastly, a task can also be
<a href="http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.retry">retried</a> from within
its own code, terminating its current run and scheduling another attempt for some future&nbsp;date.</p>
<p>Obviously, for the <code>RequestContextTask</code> to be useful, it needs to behave correctly in every situation.
Therefore we need to cover all the entry points I&#8217;ve mentioned &#8212;
the asynchronous call, a synchronous invocation, and a task&nbsp;retry:</p>
<div class="highlight"><pre><span class="k">class</span> <span class="nc">RequestContextTask</span><span class="p">(</span><span class="n">Task</span><span class="p">):</span>
    <span class="c"># ...</span>

    <span class="k">def</span> <span class="nf">apply_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">rest</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_include_context</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">RequestContextTask</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">rest</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">rest</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_include_context</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">RequestContextTask</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">rest</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">retry</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">rest</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_include_context</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">RequestContextTask</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">retry</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">rest</span><span class="p">)</span>
</pre></div>


<p>Note that <code>Task.apply_async</code> is being called internally by <code>Task.delay</code>,
so it&#8217;s only that first method that we have to&nbsp;override.</p>
<h4>Context in a&nbsp;box</h4>
<p>As you can deduce right away, the Flask-related magic is meant to go in the <code>_include_context</code> method.
The idea is to prepare arguments for the eventual invocation of <code>Flask.test_request_context</code>,
and pass them through an extra task parameter.
Those arguments are relatively uncomplicated: they are just a medley of various pieces of information
that we can easily obtain from the Flask&#8217;s <code>request</code> object:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">has_request_context</span><span class="p">,</span> <span class="n">request</span>


<span class="k">class</span> <span class="nc">RequestContextTask</span><span class="p">(</span><span class="n">Task</span><span class="p">):</span>
    <span class="n">CONTEXT_ARG_NAME</span> <span class="o">=</span> <span class="s">&#39;_flask_request_context&#39;</span>

    <span class="c"># ...</span>

    <span class="k">def</span> <span class="nf">_include_request_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Includes all the information about current HTTP request context</span>
<span class="sd">        as an additional argument to the task.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_request_context</span><span class="p">():</span>
            <span class="k">return</span>

        <span class="n">context</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">&#39;path&#39;</span><span class="p">:</span> <span class="n">request</span><span class="o">.</span><span class="n">path</span><span class="p">,</span>
            <span class="s">&#39;base_url&#39;</span><span class="p">:</span> <span class="n">request</span><span class="o">.</span><span class="n">url_root</span><span class="p">,</span>
            <span class="s">&#39;method&#39;</span><span class="p">:</span> <span class="n">request</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
            <span class="s">&#39;headers&#39;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">headers</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="s">&#39;?&#39;</span> <span class="ow">in</span> <span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="p">:</span>
            <span class="n">context</span><span class="p">[</span><span class="s">&#39;query_string&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="p">[(</span><span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;?&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):]</span>

        <span class="n">kwargs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">CONTEXT_ARG_NAME</span><span class="p">]</span> <span class="o">=</span> <span class="n">context</span>
</pre></div>


<p>On the worker side, we simply unpack them and recreate the&nbsp;context:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">make_response</span>

<span class="k">class</span> <span class="nc">RequestContextTask</span><span class="p">(</span><span class="n">Task</span><span class="p">):</span>
    <span class="c"># ...</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">call</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="nb">super</span><span class="p">(</span><span class="n">RequestContextTask</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">CONTEXT_ARG_NAME</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">has_request_context</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">call</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">app</span><span class="o">.</span><span class="n">test_request_context</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">call</span><span class="p">()</span>
            <span class="n">app</span><span class="o">.</span><span class="n">process_response</span><span class="p">(</span><span class="n">make_response</span><span class="p">(</span><span class="n">result</span> <span class="ow">or</span> <span class="s">&#39;&#39;</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">result</span>
</pre></div>


<p>The only tricky part is calling
<a href="http://flask.pocoo.org/docs/0.10/api/#flask.Flask.process_response"><code>Flask.process_response</code></a> at the end.
We need to do that for the <a href="http://flask.pocoo.org/docs/0.10/api/#flask.Flask.after_request"><code>@after_request</code> hooks</a>
to execute correctly. This is quite crucial, because those hooks are where you&#8217;d normally put important cleanup code,
like commit/rollback of the database&nbsp;transaction.</p>
<h4>Complete&nbsp;solution</h4>
<p>To see how all those code snippets fit together, see <a href="https://gist.github.com/Xion/46d739b980af14a0d3ea">this gist</a>.
You may also want to have a look at
<a href="http://flask.pocoo.org/docs/0.10/patterns/celery/">the article on Celery integration</a> in Flask docs for some tips on
how to integrate it with your own&nbsp;project.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>This isn&#8217;t strictly necessary, as Celery supports sending tasks for execution
<a href="http://docs.celeryproject.org/en/latest/reference/celery.html#celery.Celery.send_task">by explicit name</a>.
For that request to reach the worker, however,
the <a href="http://docs.celeryproject.org/en/latest/configuration.html#broker-url">task broker configuration</a>
must be correctly shared between sender and the worker.&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="http://xion.io/tag/celery.html">Celery</a>
      <a href="http://xion.io/tag/flask.html">Flask</a>
      <a href="http://xion.io/tag/python.html">Python</a>
      <a href="http://xion.io/tag/queue.html">queue</a>
      <a href="http://xion.io/tag/request-context.html">request context</a>
    </p>
  </div>
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'xionblog';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</article>

    <footer>
<p>
  &copy; Karol Kuczmarski 2018 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-27379564-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Celery task in a Flask request context",
  "headline": "Celery task in a Flask request context",
  "datePublished": "2015-11-03 22:40:00-08:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Karol Kuczmarski",
    "url": "http://xion.io/"
  },
  "image": "http://xion.io/logo.jpeg",
  "url": "http://xion.io/post/code/celery-include-flask-request-context.html",
  "description": "Celery is an asynchronous task worker that’s frequently used for background processing in Python web apps. Rather than performing a time-consuming task within the request loop, we delegate it to a queue so that a worker process can pick it up when ready. The immediate benefit is much better latency for the end user. Pros also include easier scalability, since you can adjust the number of workers to your task load. Examples of tasks that are usually best done in the background vary from fetching data through a third-party API to sending emails, and from pushing mobile notifications to pruning the database of stale records. Anything that may take more than a couple hundred milliseconds to complete — and isn’t absolutely essential to the current HTTP request — is typically a good candidate for asynchronous processing. In Celery, workers are just regular Python processes, often running the exact same code that’s powering the app’s web frontend1. But unlike most of that code, they aren’t servicing any HTTP requests — they simply run some function with given arguments, both specified by whomever sent a task for execution. Indeed, those functions don’t even know who or what asked for them to be executed. Neat, right? It is what we usually compliment as decoupling, or separation of concerns. They are valuable qualities even regardless of the UI and scaling benefits mentioned earlier. Not quite web But those qualities come with a trade-off. Task code is no longer a web frontend code: it doesn’t run within the comfy environment of our web framework of choice. Losing it may be quite unnerving, actually, because in a typical web application there will be many things tied directly to the HTTP request pipeline. After all, this is what web applications do — respond to HTTP requests — so it often makes perfect sense e.g. to marry the request flow with database transactions, committing or rolling those back according to HTTP status code that the app produced. Tasks may also require a database, though, if only to assert the expected state of the world. Similar goes for memcache, a Redis instance, or basically any resource used by the frontend code. Alas, it’s quite possible the very reason we delegate work to a task is to shift lengthy interactions with those external systems away from the UI. Obviously, we’re going to need them for that! Fake a request So one way or another, our tasks will most likely need some initialization and/or cleanup code. And since it’s probably the same code that most HTTP request handlers require and use already, why not just pretend we’re handling a request after all? In Flask, we can pull that off rather easily. The test_request_context method is conveniently provided to allow for faking the request context — that is, an execution environment for HTTP handlers. Like the name suggest, it is used mostly for testing, but there is nothing stopping us from using it in tasks run by Celery. We probably don’t want to call it directly, though. What would be better is to have Celery prepare the context first, and then run the task code as if it was an HTTP handler. For even better results, the context would preserve information extracted from the actual HTTP request, one that has sent the task for execution. Moving some work to the background would then be a trivial matter, for both the task and the original handler would operate within the same environment. Convenient? I believe so. And as I’ll demonstrate next, it isn’t very complicated to implement either. Wrap the decorator? At least one piece of the solution should stand out as pretty obvious. Since our intention is to wrap the task’s code in some additional packaging — the request context — it seems fairly natural to write our own @task decorator: import functools from myapp import app, celery def task(**kwargs): """Decorator function to apply to Celery tasks. Executes the actual task inside Flask's test request context. """ def decorator(func): """Actual decorator.""" @celery.task(**kwargs) @functools.wraps(func) def wrapped(*args, **kwargs): with app.test_request_context(): return func(*args, **kwargs) return wrapped return decorator Here, app is the Flask application, and celery is the Celery object that’s often configured alongside it. The Task class While this technique will give us a request context inside the task code, it won’t be the request context from which the task has been sent for execution. To replicate that context correctly, we need additional support on the sender side. Internally, Celery is converting every function we annotate with @task decorator into a subclass of Celery.app.task.Task. This process can be customized, for example by providing an explicit base= parameter to @task which specifies a custom Task subclass to use in place of the default one. Within that subclass, we’re free to override any functionality that we need to. In our case, we’ll scrape the current request context from Flask for all relevant information, and later use it to recreate the context in the task code. But before we get to that, let’s just create the Task subclass and move the above execution logic to it. This way, users won’t have to use a completely new @task decorator which would needlessly couple them to a specific Celery app instance: from celery import Task class RequestContextTask(Task): """Base class for tasks that run inside a Flask request context.""" abstract = True def __call__(self, *args, **kwargs): with app.test_request_context(): return super(RequestContextTask, self).__call__(*args, **kwargs) Instead, they can either set this class as base= for a specific task: @celery.task(base=RequestContextTask) def sync_user_data(user_id): # ... or make it into new default for all their tasks: celery = Celery(...) celery.Task = RequestContextTask Invocation patterns When the frontend asks for a task to be executed, it most often uses the Task.delay method. It will package a payload contaning task arguments, and send it off through a broker — usually an AMQP-based queue, such as RabbitMQ — so that a Celery worker can pick it up and actually execute. But there are other means of task invocation. We can even run it “in place”, locally and synchronously, which is especially useful for various testing scenarios. Lastly, a task can also be retried from within its own code, terminating its current run and scheduling another attempt for some future date. Obviously, for the RequestContextTask to be useful, it needs to behave correctly in every situation. Therefore we need to cover all the entry points I’ve mentioned — the asynchronous call, a synchronous invocation, and a task retry: class RequestContextTask(Task): # ... def apply_async(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .apply_async(args, kwargs, **rest) def apply(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .apply(args, kwargs, **rest) def retry(self, args=None, kwargs=None, **rest): self._include_context(kwargs) return super(RequestContextTask, self) \ .retry(args, kwargs, **rest) Note that Task.apply_async is being called internally by Task.delay, so it’s only that first method that we have to override. Context in a box As you can deduce right away, the Flask-related magic is meant to go in the _include_context method. The idea is to prepare arguments for the eventual invocation of Flask.test_request_context, and pass them through an extra task parameter. Those arguments are relatively uncomplicated: they are just a medley of various pieces of information that we can easily obtain from the Flask’s request object: from flask import has_request_context, request class RequestContextTask(Task): CONTEXT_ARG_NAME = '_flask_request_context' # ... def _include_request_context(self, kwargs): """Includes all the information about current HTTP request context as an additional argument to the task. """ if not has_request_context(): return context = { 'path': request.path, 'base_url': request.url_root, 'method': request.method, 'headers': dict(request.headers), } if '?' in request.url: context['query_string'] = request.url[(request.url.find('?') + 1):] kwargs[self.CONTEXT_ARG_NAME] = context On the worker side, we simply unpack them and recreate the context: from flask import make_response class RequestContextTask(Task): # ... def __call__(self, *args, **kwargs): call = lambda: super(RequestContextTask, self).__call__(*args, **kwargs) context = kwargs.pop(self.CONTEXT_ARG_NAME, None) if context is None or has_request_context(): return call() with app.test_request_context(**context): result = call() app.process_response(make_response(result or '')) return result The only tricky part is calling Flask.process_response at the end. We need to do that for the @after_request hooks to execute correctly. This is quite crucial, because those hooks are where you’d normally put important cleanup code, like commit/rollback of the database transaction. Complete solution To see how all those code snippets fit together, see this gist. You may also want to have a look at the article on Celery integration in Flask docs for some tips on how to integrate it with your own project. This isn’t strictly necessary, as Celery supports sending tasks for execution by explicit name. For that request to reach the worker, however, the task broker configuration must be correctly shared between sender and the worker. ↩"
}
</script></body>
</html>